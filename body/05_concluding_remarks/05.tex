\section{Concluding Remarks}
Globally, the COVID-19 pandemic had a substantial impact on people's health due to a sharp rise in fatalities. Since the start of the global epidemic, deep- and machine-learning techniques have been of great assistance. Several COVID-19 categorization methods have been put forth in this work. The first method uses a speech-based technology to listen for COVID-19 in the cough, breath, and voice of the patient. The second approach uses a medical image-based technology that can identify COVID-19 in chest X-ray pictures of patients. The final method is a combined speech-image-based model that can identify COVID-19 from both chest X-ray images and audio spectrograms. The primary functions of the system are to find, identify, and categorize any COVID-19 infection. Additionally, the speech-based model's hyperparameters have been manually adjusted using grid searches for both the image-based and speech-image-based models. Additionally, it has been found that modifying the MFCCs improves the model's accuracy. The MFCC and LSTM models have been conjugated in the suggested speech model, which has demonstrated impressive competency in detecting COVID-19. This is shown by its accuracy, precision, F1-score, and recall accuracy rates of each 98.9%, exceeding a number of earlier systems and methods. Furthermore, there is a bias toward normal labels in the chest X-ray sample. This has a detrimental effect on the system's accuracy.

The ideal CNN model hyperparameters have also been found using the grid search method. The CNN VGG16 model has therefore achieved an accuracy of 85.25%. The accuracy of the system was improved to 89.64% by using fine-tuning approaches on VGG16, exceeding all other suggested models. Finally, it is clear that using either the speech-based model alone or the image-based model alone results in more accuracy than using both models at once. Therefore, for diagnostic purposes, it is not necessary to integrate the two models into a new model.

Due to the modest amount of the voice and image datasets in this work, the overall performance of the suggested methods is less than optimal. This is because of the stringent limitations that have made it difficult to gather enough audio files. Thus, to increase the dataset and improve the model's performance, data augmentation approaches have been applied.

There are numerous ways to improve the proposed systems. For example, a hybrid cascaded CNN-LSTM classifier can be used to improve the functionality of the speech-based system. Furthermore, the imbalanced class problem, which has hampered the performance of the speech-image-based model, can be resolved.
Additionally, a dataset expansion option might be practicable soon, which would greatly improve the system's accuracy. The problem of unbalanced classes can also be solved by using unbalanced treatments. Finally, by examining the changes in the respiratory system following the administration of the present vaccines, the suggested image-based model can be applied to the creation of drugs and vaccines.
